{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting for Framing Drift Analysis\n",
    "\n",
    "**Purpose:** Split LRC_articles.parquet into train/validation/test/drift/human_validation sets\n",
    "\n",
    "**Splits:**\n",
    "- Train: 2015-2016 (for model fine-tuning)\n",
    "- Validation: 2017 H1 (for threshold tuning)\n",
    "- Test: 2017 H2 (for model evaluation)\n",
    "- Drift Analysis: 2018-2021 (for measuring framing drift)\n",
    "- Human Validation: 100 stratified articles (for model validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs('data/processed', exist_ok=True)\n",
    "os.makedirs('data/human_labels', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load parquet file\ndf = pd.read_parquet('LRC_articles.parquet')\n\n# Convert date and add temporal columns\ndf['date'] = pd.to_datetime(df['date'])\ndf['year'] = df['date'].dt.year\ndf['year_quarter'] = df['date'].dt.to_period('Q')\n\n# Add word count for stratified sampling\ndf['word_count'] = df['content'].fillna('').str.split().str.len()\n\n# Create unique ID for each article (using index)\ndf['article_id'] = df.index\n\nprint(f\"Total articles loaded: {len(df):,}\")\nprint(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\nprint(f\"Outlets: {df['outlet_name'].nunique()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Temporal Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal splits based on year\n",
    "train_df = df[df['year'].isin([2015, 2016])].copy()\n",
    "val_df = df[(df['year'] == 2017) & (df['date'] < '2017-07-01')].copy()\n",
    "test_df = df[(df['year'] == 2017) & (df['date'] >= '2017-07-01')].copy()\n",
    "drift_df = df[df['year'].isin([2018, 2019, 2020, 2021])].copy()\n",
    "\n",
    "# Add split labels\n",
    "train_df['split'] = 'train'\n",
    "val_df['split'] = 'validation'\n",
    "test_df['split'] = 'test'\n",
    "drift_df['split'] = 'drift'\n",
    "\n",
    "print(\"Temporal Splits:\")\n",
    "print(f\"Train (2015-2016):       {len(train_df):,} articles\")\n",
    "print(f\"Validation (2017 H1):    {len(val_df):,} articles\")\n",
    "print(f\"Test (2017 H2):          {len(test_df):,} articles\")\n",
    "print(f\"Drift (2018-2021):       {len(drift_df):,} articles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample 100 Articles for Human Validation\n",
    "\n",
    "Stratified by:\n",
    "- Political bias (Left/Center/Right)\n",
    "- Time period (Early/Mid/Late)\n",
    "- Article length (Short/Medium/Long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stratification columns\n",
    "drift_df['bias_category'] = drift_df['bias'].map({\n",
    "    'Left': 'Left',\n",
    "    'Lean Left': 'Center',\n",
    "    'Center': 'Center',\n",
    "    'Lean Right': 'Right',\n",
    "    'Right': 'Right'\n",
    "})\n",
    "\n",
    "drift_df['time_period'] = pd.cut(\n",
    "    drift_df['year'],\n",
    "    bins=[2017, 2018, 2020, 2022],\n",
    "    labels=['Early', 'Mid', 'Late']\n",
    ")\n",
    "\n",
    "drift_df['length_bin'] = pd.cut(\n",
    "    drift_df['word_count'],\n",
    "    bins=[0, 400, 800, 100000],\n",
    "    labels=['Short', 'Medium', 'Long']\n",
    ")\n",
    "\n",
    "# Stratified sample\n",
    "human_val_df = (\n",
    "    drift_df\n",
    "    .dropna(subset=['bias_category', 'time_period', 'length_bin'])\n",
    "    .groupby(['bias_category', 'time_period', 'length_bin'], group_keys=False)\n",
    "    .apply(lambda x: x.sample(min(len(x), 4), random_state=42))\n",
    "    .sample(n=min(100, len(drift_df)), random_state=42)\n",
    ").copy()\n",
    "\n",
    "human_val_df['split'] = 'human_validation'\n",
    "\n",
    "print(f\"\\nHuman Validation Sample: {len(human_val_df)} articles\")\n",
    "print(\"\\nBreakdown by Bias:\")\n",
    "print(human_val_df['bias_category'].value_counts())\n",
    "print(\"\\nBreakdown by Time Period:\")\n",
    "print(human_val_df['time_period'].value_counts())\n",
    "print(\"\\nBreakdown by Length:\")\n",
    "print(human_val_df['length_bin'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Human Validation Articles from Drift Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove human validation articles from drift analysis set\n",
    "drift_df = drift_df[~drift_df.index.isin(human_val_df.index)].copy()\n",
    "\n",
    "print(f\"Drift Analysis (after removing human val): {len(drift_df):,} articles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save All Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Save to parquet\ntrain_df.to_parquet('data/processed/train.parquet', index=False)\nval_df.to_parquet('data/processed/validation.parquet', index=False)\ntest_df.to_parquet('data/processed/test.parquet', index=False)\ndrift_df.to_parquet('data/processed/drift_analysis.parquet', index=False)\nhuman_val_df.to_parquet('data/processed/human_validation_sample.parquet', index=False)\n\nprint(\"âœ… Saved all parquet files to data/processed/\")"
  },
  {
   "cell_type": "markdown",
   "source": "## Create Individual Text Files for Human Validation\n\nExport each article to a separate .txt file for easier reading",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import json\n\n# Load frame names from model\nwith open('best/frames.json', 'r') as f:\n    frames = json.load(f)\n\nprint(f\"Loaded {len(frames)} frame categories: {frames}\")\n\n# Create annotation dataframe\nannotation_df = human_val_df[['article_id', 'outlet_name', 'bias', 'date', 'word_count']].copy()\nannotation_df['date'] = annotation_df['date'].dt.strftime('%Y-%m-%d')\n\n# Add empty columns for each frame (annotators will fill with 0 or 1)\nfor frame in frames:\n    annotation_df[f'frame_{frame}'] = ''\n\n# Add notes and confidence columns\nannotation_df['notes'] = ''\nannotation_df['confidence'] = ''  # low/medium/high\n\n# Save to CSV\nannotation_df.to_csv('data/human_labels/annotation_template.csv', index=False)\n\nprint(f\"\\nâœ… Created annotation template with {len(annotation_df.columns)} columns\")\nprint(f\"   - 5 metadata columns (article_id, outlet, bias, date, word_count)\")\nprint(f\"   - {len(frames)} frame columns (frame_*)\")\nprint(f\"   - 2 annotation columns (notes, confidence)\")\nprint(f\"\\nðŸ“‹ Annotation Workflow:\")\nprint(f\"   1. Open article: data/human_labels/articles/article_[article_id].txt\")\nprint(f\"   2. Read the article\")\nprint(f\"   3. Mark frames in annotation_template.csv (enter 0 or 1)\")\nprint(f\"   4. Add notes/confidence if needed\")\nprint(f\"   5. Save as annotation_[your_name].csv\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Create Annotation Spreadsheet (without full text)\n\nCreate a CSV with metadata + 14 frame columns for annotation",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Create directory for article text files\nos.makedirs('data/human_labels/articles', exist_ok=True)\n\n# Create individual text files\nfor idx, row in human_val_df.iterrows():\n    filename = f\"data/human_labels/articles/article_{row['article_id']}.txt\"\n    \n    with open(filename, 'w', encoding='utf-8') as f:\n        # Header with metadata\n        f.write(\"=\"*70 + \"\\n\")\n        f.write(f\"Article ID: {row['article_id']}\\n\")\n        f.write(f\"Outlet: {row['outlet_name']}\\n\")\n        f.write(f\"Political Bias: {row['bias']}\\n\")\n        f.write(f\"Date: {row['date'].strftime('%Y-%m-%d')}\\n\")\n        f.write(f\"Word Count: {row['word_count']}\\n\")\n        f.write(\"=\"*70 + \"\\n\\n\")\n        \n        # Article content\n        f.write(row['content'])\n\nprint(f\"âœ… Created {len(human_val_df)} text files in data/human_labels/articles/\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"FINAL SPLIT SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Train:             {len(train_df):,} articles (2015-2016)\")\n",
    "print(f\"Validation:        {len(val_df):,} articles (2017 H1)\")\n",
    "print(f\"Test:              {len(test_df):,} articles (2017 H2)\")\n",
    "print(f\"Drift Analysis:    {len(drift_df):,} articles (2018-2021)\")\n",
    "print(f\"Human Validation:  {len(human_val_df):,} articles (sampled from drift)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total:             {len(train_df) + len(val_df) + len(test_df) + len(drift_df) + len(human_val_df):,}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification: Check for Overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify no overlaps between splits\n",
    "train_ids = set(train_df.index)\n",
    "val_ids = set(val_df.index)\n",
    "test_ids = set(test_df.index)\n",
    "drift_ids = set(drift_df.index)\n",
    "human_val_ids = set(human_val_df.index)\n",
    "\n",
    "print(\"Checking for overlaps between splits...\")\n",
    "print(f\"Train âˆ© Val: {len(train_ids & val_ids)}\")\n",
    "print(f\"Train âˆ© Test: {len(train_ids & test_ids)}\")\n",
    "print(f\"Train âˆ© Drift: {len(train_ids & drift_ids)}\")\n",
    "print(f\"Val âˆ© Test: {len(val_ids & test_ids)}\")\n",
    "print(f\"Val âˆ© Drift: {len(val_ids & drift_ids)}\")\n",
    "print(f\"Test âˆ© Drift: {len(test_ids & drift_ids)}\")\n",
    "print(f\"Drift âˆ© Human Val: {len(drift_ids & human_val_ids)}\")\n",
    "print(\"\\nâœ… All should be 0 (except Drift âˆ© Human Val)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}